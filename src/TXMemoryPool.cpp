//
// @file TXMemoryPool.cpp
// @brief é«˜æ€§èƒ½å†…å­˜æ± ç®¡ç†å™¨å®ç°
//

#include "TinaXlsx/TXMemoryPool.hpp"
#include <algorithm>
#include <cassert>

namespace TinaXlsx {

// ==================== TXMemoryPool::Chunk å®ç° ====================

TXMemoryPool::Chunk::Chunk(size_t blockSize, size_t blockCount) {
    size_t totalSize = blockSize * blockCount;
    memory = std::make_unique<uint8_t[]>(totalSize);
    
    // åˆå§‹åŒ–ç©ºé—²é“¾è¡¨
    uint8_t* ptr = memory.get();
    freeList = reinterpret_cast<Block*>(ptr);
    freeCount = blockCount;
    
    Block* current = freeList;
    for (size_t i = 0; i < blockCount - 1; ++i) {
        Block* next = reinterpret_cast<Block*>(ptr + (i + 1) * blockSize);
        current->next = next;
        current = next;
    }
    current->next = nullptr;
}

// ==================== TXMemoryPool å®ç° ====================

TXMemoryPool::TXMemoryPool(const PoolConfig& config)
    : config_(config) {
    // ğŸš€ ä¼˜åŒ–ï¼šå»¶è¿Ÿåˆ†é…ï¼Œåªåœ¨éœ€è¦æ—¶åˆ›å»ºchunk
    // ä¸å†é¢„åˆ†é…chunkï¼Œå‡å°‘åŸºç¡€å†…å­˜ä½¿ç”¨
}

TXMemoryPool::~TXMemoryPool() {
    clear();
}

void* TXMemoryPool::allocate(size_t size) {
    if (size > config_.blockSize) {
        return nullptr; // è¶…å‡ºå—å¤§å°é™åˆ¶
    }
    
    std::unique_lock<std::mutex> lock(mutex_, std::defer_lock);
    if (config_.threadSafe) {
        lock.lock();
    }
    
    // å°è¯•ä»å…¨å±€ç©ºé—²é“¾è¡¨åˆ†é…
    if (globalFreeList_) {
        Block* block = globalFreeList_;
        globalFreeList_ = block->next;
        
        size_t allocated = config_.blockSize;
        totalAllocated_ += allocated;
        currentUsage_ += allocated;
        
        size_t current = currentUsage_.load();
        size_t peak = peakUsage_.load();
        while (current > peak && !peakUsage_.compare_exchange_weak(peak, current)) {
            peak = peakUsage_.load();
        }
        
        return block;
    }
    
    // å°è¯•ä»ç°æœ‰chunkåˆ†é…
    for (auto& chunk : chunks_) {
        if (chunk->freeCount > 0) {
            Block* block = allocateFromChunk(chunk.get());
            if (block) {
                size_t allocated = config_.blockSize;
                totalAllocated_ += allocated;
                currentUsage_ += allocated;
                
                size_t current = currentUsage_.load();
                size_t peak = peakUsage_.load();
                while (current > peak && !peakUsage_.compare_exchange_weak(peak, current)) {
                    peak = peakUsage_.load();
                }
                
                return block;
            }
        }
    }
    
    // åˆ›å»ºæ–°chunk
    if (config_.autoGrow && chunks_.size() < config_.maxChunks) {
        auto newChunk = std::unique_ptr<Chunk>(createChunk());
        Block* block = allocateFromChunk(newChunk.get());
        chunks_.push_back(std::move(newChunk));
        
        if (block) {
            size_t allocated = config_.blockSize;
            totalAllocated_ += allocated;
            currentUsage_ += allocated;
            
            size_t current = currentUsage_.load();
            size_t peak = peakUsage_.load();
            while (current > peak && !peakUsage_.compare_exchange_weak(peak, current)) {
                peak = peakUsage_.load();
            }
        }
        
        return block;
    }
    
    return nullptr; // åˆ†é…å¤±è´¥
}

void TXMemoryPool::deallocate(void* ptr) {
    if (!ptr || !isFromPool(ptr)) {
        return;
    }
    
    std::unique_lock<std::mutex> lock(mutex_, std::defer_lock);
    if (config_.threadSafe) {
        lock.lock();
    }
    
    // æ·»åŠ åˆ°å…¨å±€ç©ºé—²é“¾è¡¨
    Block* block = static_cast<Block*>(ptr);
    block->next = globalFreeList_;
    globalFreeList_ = block;
    
    size_t deallocated = config_.blockSize;
    totalDeallocated_ += deallocated;
    currentUsage_ -= deallocated;
}

TXMemoryPool::PoolStats TXMemoryPool::getStats() const {
    std::unique_lock<std::mutex> lock(mutex_, std::defer_lock);
    if (config_.threadSafe) {
        lock.lock();
    }
    
    PoolStats stats;
    stats.totalAllocated = totalAllocated_.load();
    stats.totalDeallocated = totalDeallocated_.load();
    stats.currentUsage = currentUsage_.load();
    stats.peakUsage = peakUsage_.load();
    stats.totalChunks = chunks_.size();
    
    // è®¡ç®—ç©ºé—²å—æ•°
    Block* current = globalFreeList_;
    while (current) {
        stats.freeBlocks++;
        current = current->next;
    }
    
    for (const auto& chunk : chunks_) {
        stats.freeBlocks += chunk->freeCount;
    }
    
    return stats;
}

void TXMemoryPool::clear() {
    std::unique_lock<std::mutex> lock(mutex_, std::defer_lock);
    if (config_.threadSafe) {
        lock.lock();
    }

    chunks_.clear();
    globalFreeList_ = nullptr;

    totalAllocated_ = 0;
    totalDeallocated_ = 0;
    currentUsage_ = 0;
    peakUsage_ = 0;
}

void TXMemoryPool::shrink() {
    std::unique_lock<std::mutex> lock(mutex_, std::defer_lock);
    if (config_.threadSafe) {
        lock.lock();
    }

    // ç§»é™¤å®Œå…¨ç©ºé—²çš„chunk
    chunks_.erase(
        std::remove_if(chunks_.begin(), chunks_.end(),
            [this](const std::unique_ptr<Chunk>& chunk) {
                return chunk->freeCount == config_.blocksPerChunk;
            }),
        chunks_.end()
    );
}

TXMemoryPool::Chunk* TXMemoryPool::createChunk() {
    return new Chunk(config_.blockSize, config_.blocksPerChunk);
}

TXMemoryPool::Block* TXMemoryPool::allocateFromChunk(Chunk* chunk) {
    if (chunk->freeCount == 0 || !chunk->freeList) {
        return nullptr;
    }
    
    Block* block = chunk->freeList;
    chunk->freeList = block->next;
    chunk->freeCount--;
    
    return block;
}

void TXMemoryPool::deallocateToChunk(void* ptr) {
    // è¿™ä¸ªæ–¹æ³•åœ¨å½“å‰å®ç°ä¸­ä¸ä½¿ç”¨
    // æ‰€æœ‰é‡Šæ”¾éƒ½é€šè¿‡å…¨å±€ç©ºé—²é“¾è¡¨å¤„ç†
}

bool TXMemoryPool::isFromPool(void* ptr) const {
    if (!ptr) return false;
    
    uint8_t* bytePtr = static_cast<uint8_t*>(ptr);
    
    for (const auto& chunk : chunks_) {
        uint8_t* chunkStart = chunk->memory.get();
        uint8_t* chunkEnd = chunkStart + (config_.blockSize * config_.blocksPerChunk);
        
        if (bytePtr >= chunkStart && bytePtr < chunkEnd) {
            // æ£€æŸ¥æ˜¯å¦å¯¹é½åˆ°å—è¾¹ç•Œ
            size_t offset = bytePtr - chunkStart;
            return (offset % config_.blockSize) == 0;
        }
    }
    
    return false;
}

// æ³¨æ„ï¼šTXStringPool å®ç°å·²ç§»åŠ¨åˆ° TXCompactCell.cpp ä¸­





// ==================== TXMemoryManager å®ç° ====================

TXMemoryManager& TXMemoryManager::instance() {
    static TXMemoryManager instance;
    return instance;
}

TXMemoryManager::TXMemoryManager() {
    // åˆ›å»ºé»˜è®¤æ± 
    generalPool_ = std::make_unique<TXMemoryPool>();
}

TXMemoryManager::~TXMemoryManager() {
    clearAll();
}

TXMemoryPool& TXMemoryManager::getGeneralPool() {
    return *generalPool_;
}

TXMemoryPool& TXMemoryManager::getPool(size_t blockSize) {
    std::lock_guard<std::mutex> lock(mutex_);

    auto it = sizedPools_.find(blockSize);
    if (it != sizedPools_.end()) {
        return *it->second;
    }

    // åˆ›å»ºæ–°çš„æŒ‡å®šå¤§å°çš„æ± 
    TXMemoryPool::PoolConfig config;
    config.blockSize = blockSize;
    config.blocksPerChunk = std::max(size_t(64), 4096 / blockSize);

    auto pool = std::make_unique<TXMemoryPool>(config);
    TXMemoryPool* poolPtr = pool.get();
    sizedPools_[blockSize] = std::move(pool);

    return *poolPtr;
}

void TXMemoryManager::clearAll() {
    std::lock_guard<std::mutex> lock(mutex_);

    if (generalPool_) {
        generalPool_->clear();
    }

    for (auto& [size, pool] : sizedPools_) {
        pool->clear();
    }
    sizedPools_.clear();
}

void TXMemoryManager::shrinkAll() {
    std::lock_guard<std::mutex> lock(mutex_);

    if (generalPool_) {
        generalPool_->shrink();
    }

    for (auto& [size, pool] : sizedPools_) {
        pool->shrink();
    }
}

TXMemoryManager::GlobalStats TXMemoryManager::getGlobalStats() const {
    std::lock_guard<std::mutex> lock(mutex_);

    GlobalStats stats;

    if (generalPool_) {
        stats.generalPool = generalPool_->getStats();
        stats.totalMemoryUsage += stats.generalPool.currentUsage;
    }

    stats.totalPools = 1 + sizedPools_.size(); // general + sized pools

    for (const auto& [size, pool] : sizedPools_) {
        auto poolStats = pool->getStats();
        stats.totalMemoryUsage += poolStats.currentUsage;
    }

    return stats;
}

} // namespace TinaXlsx
